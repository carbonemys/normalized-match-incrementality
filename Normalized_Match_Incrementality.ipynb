{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrLmr59U4lve"
      },
      "source": [
        "# Normalized Geo Matchâ„¢ï¸\n",
        "Developed by *Bas Baudoin* for *[Happy Horizon](https://happyhorizon.com/)â„¢ï¸*\n",
        "\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/10hu9TqJztZTSwTKOfhE5foRPEL3BY38B#scrollTo=OrLmr59U4lve)\n",
        "\n",
        "- Assignment values: **`1 = treatment`** (B) and  **`2 = control`** (A)\n",
        "- Checkmark chapters (âœ”ï¸) are for manual validation. Easily take a look if all data still looks okay after transformations\n",
        "- Input dataset format:\n",
        "\n",
        "| date       | geo | response   | cost    | pair | assignment | Region       |\n",
        "|------------|-----|------------|---------|------|------------|--------------|\n",
        "| 2023-12-01 | 3.0 | 374.779999 | 0.0     | 3.0  | 2.0        | Friesland    |\n",
        "| 2023-12-01 | 1.0 | 76.42      | 0.84    | 2.0  | 1.0        | Drenthe      |\n",
        "| 2023-12-01 | 8.0 | 4432.929997| 0.0     | 5.0  | 2.0        | North Holland|\n",
        "| 2023-12-01 | 4.0 | 972.620001 | 0.0     | 4.0  | 2.0        | Gelderland   |\n",
        "| 2023-12-01 | 10.0| 2469.579999| 12.42   | 5.0  | 1.0        | South Holland|\n",
        "| 2023-12-01 | 11.0| 1214.31    | 4.690252| 4.0  | 1.0        | Utrecht      |\n",
        "| 2023-12-01 | 6.0 | 69.96      | 0.0     | 2.0  | 2.0        | Limburg      |\n",
        "| 2023-12-01 | 5.0 | 160.19     | 4.39    | 3.0  | 1.0        | Groningen    |\n",
        "| 2023-12-01 | 2.0 | 174.31     | 0.0     | 1.0  | 2.0        | Flevoland    |\n",
        "| 2023-12-02 | 8.0 | 2404.19    | 0.0     | 5.0  | 2.0        | North Holland|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCSVeJWjfLiA"
      },
      "source": [
        "## ðŸ“¦ Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHaEtbzleCX4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmdTpz-Pg2UD"
      },
      "source": [
        "## âš™ï¸ Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_5WNUreghE-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "ðŸ’¡  Recommendation: save this config file locally for future use, along with the csv file\n",
        "\n",
        "    # Add names for reference:\n",
        "    Client name: clientX\n",
        "    Test name: upper funnel NL 2024\n",
        "    Description: containing data halfway, no cooldown\n",
        "'''\n",
        "config = {\n",
        "    'design_eval_start_date': '2024-01-01',\n",
        "    'design_eval_end_date': '2024-03-01',\n",
        "\n",
        "    'test_start_date': '2024-03-10',\n",
        "    'test_end_date': '2024-05-26',\n",
        "\n",
        "    'cooldown_end_date': '2024-05-27', # Only used for visuals\n",
        "\n",
        "    'pairs_include': '1,2', # Select pairs e.g '1,2,3'\n",
        "\n",
        "    'file_name': 'upperf_2024-05-28_revenue.csv',\n",
        "    'response_name': 'Revenue', # E.g. 'Revenue' or 'Sessions'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj9HCTWcfOOx"
      },
      "source": [
        "## ðŸªŸ Prepare dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hpzEV_UdfUWH",
        "outputId": "4b555038-c710-4ae5-95c6-a1ea0ec2599b"
      },
      "outputs": [],
      "source": [
        "# Convert config dates\n",
        "test_start_date = pd.to_datetime(config['test_start_date'])\n",
        "test_end_date = pd.to_datetime(config['test_end_date'])\n",
        "cooldown_end_date = pd.to_datetime(config['cooldown_end_date'])\n",
        "design_eval_start_date = pd.to_datetime(config['design_eval_start_date'])\n",
        "design_eval_end_date = pd.to_datetime(config['design_eval_end_date'])\n",
        "\n",
        "# Prepare and check initial dataframe\n",
        "data = pd.read_csv(config['file_name'])\n",
        "\n",
        "# Basic type transformations\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "\n",
        "# Filter the data to include only rows after the design start date\n",
        "data = data[data['date'] >= design_eval_start_date]\n",
        "\n",
        "# Convert numeric columns\n",
        "for colname in ['geo', 'pair', 'assignment', 'response', 'cost']:\n",
        "  data[colname] = pd.to_numeric(data[colname])\n",
        "\n",
        "# Convert pairs string to array\n",
        "pairs_include = [] if config['pairs_include'] == '' else [\n",
        "    int(re.sub(r'\\W+', '', x)) for x in config['pairs_include'].split(',')\n",
        "]\n",
        "\n",
        "# Keep only used pairs\n",
        "data = data[data['pair'].isin(pairs_include)]\n",
        "\n",
        "# Preview\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1UBcXKvQN_9"
      },
      "source": [
        "### (optional) Switch assignment\n",
        "ðŸ’¡ Check if your treatment group = 1 and control = 2, otherwise run the code below to switch it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNhIeOjqfdTJ"
      },
      "outputs": [],
      "source": [
        "# âš™ï¸ Optional switch assignment, for debugging purposes\n",
        "SWITCH_ASSIGNMENT = True # Default False\n",
        "if (SWITCH_ASSIGNMENT):\n",
        "    data['assignment'] = data['assignment'].map({1: 2, 2: 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBR2yVT_tzaI"
      },
      "source": [
        "## âœ”ï¸ (optional) Validate pairs\n",
        "\n",
        "Manually check the table if everything looks valid."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b68df1P2ft9s",
        "outputId": "396d5452-f743-4ae3-fd76-e7d5865e4c47"
      },
      "outputs": [],
      "source": [
        "# âœ”ï¸ CHECK: Overview of used regions\n",
        "validate_grouped_df = data.groupby(['Region', 'pair']).agg({'response': 'sum', 'cost': 'sum', 'assignment': 'first'}).reset_index()\n",
        "validate_grouped_df.sort_values(by='pair')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIMStFmltq_8"
      },
      "source": [
        "## ðŸªŸ Create normalized dataframe\n",
        "\n",
        "The goal is to align pairs so we can calculate the incrementality as precisely as possible. There are several methods to do this, but I found the normalization based on each timeseries' maximum value the most robust. If your data contains outliers, you might want to use the smooth max scaling method. An alternate method is to align the timeseries based on the test start date. I suggest trying out different methods and look at the charts in the following steps what seems to align best for your data.\n",
        "\n",
        "Run one of the four options."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z75UvOFG3I-"
      },
      "source": [
        "### Option 1: max scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1hz071Ptsqp",
        "outputId": "6927be1c-04b8-46d3-e4a9-f3cb1fe303ea"
      },
      "outputs": [],
      "source": [
        "# Ensure the dates in the config are converted to datetime if not already\n",
        "design_eval_start_date = pd.to_datetime(config['design_eval_start_date'])\n",
        "design_eval_end_date = pd.to_datetime(config['design_eval_end_date'])\n",
        "\n",
        "# Assuming 'data' is your DataFrame and it has a datetime column named 'date'\n",
        "norm_df = data.copy()\n",
        "\n",
        "def normalize_and_get_multipliers(norm_df, column, start_date, end_date):\n",
        "    # Filter the DataFrame for the design evaluation period\n",
        "    period_df = norm_df[(norm_df['date'] >= start_date) & (norm_df['date'] <= end_date)]\n",
        "\n",
        "    # Group by 'geo' and 'pair', and calculate the max value within the specified period\n",
        "    grouped = period_df.groupby(['geo', 'pair'])[column]\n",
        "    max_vals = grouped.transform('max')\n",
        "\n",
        "    # Use the max values from the filtered period to normalize the entire dataset\n",
        "    normalized_values = norm_df[column] / norm_df.groupby(['geo', 'pair'])[column].transform(lambda x: max_vals.reindex(x.index, method='ffill'))\n",
        "\n",
        "    return normalized_values, max_vals\n",
        "\n",
        "# Apply normalization to 'cost' and 'response' columns for each region using the design evaluation period\n",
        "norm_df['cost_norm'], norm_df['cost_max'] = normalize_and_get_multipliers(norm_df, 'cost', design_eval_start_date, design_eval_end_date)\n",
        "norm_df['response_norm'], norm_df['response_max'] = normalize_and_get_multipliers(norm_df, 'response', design_eval_start_date, design_eval_end_date)\n",
        "\n",
        "norm_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIwWl118HAFL"
      },
      "source": [
        "### Option 2: smooth max scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNDUD9vxI4yI",
        "outputId": "5f98352f-d070-4fae-de2a-3426b0ed35ec"
      },
      "outputs": [],
      "source": [
        "norm_df = data.copy()\n",
        "\n",
        "def normalize_and_get_multipliers(norm_df, column):\n",
        "    # Apply 7-day rolling average and then group by 'geo' and 'pair'\n",
        "    rolled = norm_df.groupby(['geo', 'pair'])[column].rolling(window=7, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "    norm_df[f'{column}_rolled'] = rolled\n",
        "\n",
        "    # Group by 'geo' and 'pair' again to find the max of the rolling averages\n",
        "    max_vals = norm_df.groupby(['geo', 'pair'])[f'{column}_rolled'].transform('max')\n",
        "\n",
        "    # Normalize original column values by these max values\n",
        "    normalized_values = norm_df[column] / max_vals\n",
        "    return normalized_values, max_vals\n",
        "\n",
        "# Apply normalization to 'cost' and 'response' columns for each region\n",
        "norm_df[\"cost_norm\"], norm_df[\"cost_max\"] = normalize_and_get_multipliers(norm_df, \"cost\")\n",
        "norm_df[\"response_norm\"], norm_df[\"response_max\"] = normalize_and_get_multipliers(norm_df, \"response\")\n",
        "\n",
        "norm_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC7M3altG8yl"
      },
      "source": [
        "### Option 3: start date scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZBF1lLOAj0h",
        "outputId": "5b308cfc-2a96-4d36-ce98-5aab67f66087"
      },
      "outputs": [],
      "source": [
        "# ! Error when cost or response = 0 at test_start_date\n",
        "\n",
        "norm_df = data.copy()\n",
        "\n",
        "def normalize_based_on_date(norm_df, column, date):\n",
        "    start_date_mask = norm_df['date'] == date\n",
        "\n",
        "    # Group by 'geo' and 'pair', then apply the normalization\n",
        "    def normalize(group):\n",
        "        start_value = group.loc[start_date_mask & (group['geo'] == group.name[0]) & (group['pair'] == group.name[1]), column].iloc[0]\n",
        "        return group[column] / start_value\n",
        "\n",
        "    normalized_values = norm_df.groupby(['geo', 'pair']).apply(normalize).reset_index(level=[0,1], drop=True)\n",
        "    return normalized_values.fillna(0)\n",
        "\n",
        "# Apply the new normalization to 'cost' and 'response' columns\n",
        "norm_df['cost_norm'] = normalize_based_on_date(norm_df, 'cost', config['test_start_date'])\n",
        "norm_df['response_norm'] = normalize_based_on_date(norm_df, 'response', config['test_start_date'])\n",
        "\n",
        "norm_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZltwEuZHC-f"
      },
      "source": [
        "### Option 4: smooth start date scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZMDWGH5dLJIe",
        "outputId": "1aeae94b-1492-4549-cb35-670fc6b7ffb3"
      },
      "outputs": [],
      "source": [
        "norm_df = data.copy()\n",
        "\n",
        "def normalize_based_on_date(norm_df, column, date):\n",
        "    # Calculate 7-day rolling average for the column\n",
        "    rolled = norm_df.groupby(['geo', 'pair'])[column].rolling(window=7, min_periods=1).mean().reset_index(level=[0,1], drop=True)\n",
        "    norm_df[f'{column}_rolled'] = rolled\n",
        "\n",
        "    # Create a mask for the start date\n",
        "    start_date_mask = norm_df['date'] == date\n",
        "\n",
        "    # Group by 'geo' and 'pair', then apply the normalization\n",
        "    def normalize(group):\n",
        "        start_value = group.loc[start_date_mask & (group['geo'] == group.name[0]) & (group['pair'] == group.name[1]), f'{column}_rolled'].iloc[0]\n",
        "        return group[column] / start_value\n",
        "\n",
        "    normalized_values = norm_df.groupby(['geo', 'pair']).apply(normalize).reset_index(level=[0,1], drop=True)\n",
        "    return normalized_values.fillna(0)\n",
        "\n",
        "# Apply the new normalization to 'cost' and 'response' columns\n",
        "norm_df['cost_norm'] = normalize_based_on_date(norm_df, 'cost', config['test_start_date'])\n",
        "norm_df['response_norm'] = normalize_based_on_date(norm_df, 'response', config['test_start_date'])\n",
        "\n",
        "norm_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxpSWmPfiCuA"
      },
      "source": [
        "## ðŸªŸ Create control vs. treatment pairs dataframe\n",
        "\n",
        "In order to be able to compare pairs, a new dataframe has to be created where the data of each of the pairs is on the same row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S3LizOykvGu",
        "outputId": "aa09d6fd-fb5b-4cb3-ac48-e8d0fb2abbf6"
      },
      "outputs": [],
      "source": [
        "pairs_df = norm_df.copy()\n",
        "\n",
        "# Type modification\n",
        "pairs_df['pair'] = pairs_df['pair'].astype(int)\n",
        "pairs_df['assignment'] = pairs_df['assignment'].astype(int)\n",
        "pairs_df['pair'] = pairs_df['pair'].astype(str)\n",
        "pairs_df['assignment'] = pairs_df['assignment'].astype(str)\n",
        "\n",
        "# Pivot the table and create column names\n",
        "pairs_df = pairs_df.pivot_table(index=['date', 'pair'], columns='assignment', values=['geo', 'response', 'cost', 'Region', 'cost_norm', 'response_norm'], aggfunc='first')\n",
        "\n",
        "# Create readable names for new columns\n",
        "pairs_df.columns = ['_'.join(map(str, col)).strip() for col in pairs_df.columns.values]\n",
        "rename_dict = {\n",
        "    '_1': '_treatment',\n",
        "    '_2': '_control'\n",
        "}\n",
        "for old_suffix, new_suffix in rename_dict.items():\n",
        "    pairs_df.columns = pairs_df.columns.str.replace(old_suffix, new_suffix)\n",
        "\n",
        "pairs_df.reset_index(inplace=True)\n",
        "\n",
        "pairs_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R89twuFkIhe1"
      },
      "source": [
        "## âœ”ï¸ Charting\n",
        "\n",
        "This is the first main output of the analysis, as a final result and for inspection. Check for the following things:\n",
        "\n",
        "- [ ] Do the pairs align in the test periods?\n",
        "- [ ] Are the interventions visible? For example when pausing one of the pairs in the experiment, the cost line should drop to 0 at the test date.\n",
        "- [ ] Do the pair lines align sufficiently at the start dates?\n",
        "\n",
        "If the data doesn't align well, you can either choose another scaling option and/or choose to leave out certain pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Osj4hKlAIlGj",
        "outputId": "59bb6079-a193-41d4-e1a7-6c7596d4b98f"
      },
      "outputs": [],
      "source": [
        "df_plot = pairs_df.copy()\n",
        "\n",
        "# âš™ï¸ Option to smootth the results\n",
        "SMOOTH_RESULTS = False\n",
        "ROLLING_DAYS = 4 # Default 4 if enabled, more days = smoother\n",
        "\n",
        "if (SMOOTH_RESULTS):\n",
        "    df_plot['response_norm_treatment'] = df_plot['response_norm_treatment'].rolling(ROLLING_DAYS).mean()\n",
        "    df_plot['response_norm_control'] = df_plot['response_norm_control'].rolling(ROLLING_DAYS).mean()\n",
        "    df_plot['cost_norm_treatment'] = df_plot['cost_norm_treatment'].rolling(ROLLING_DAYS).mean()\n",
        "    df_plot['cost_norm_control'] = df_plot['cost_norm_control'].rolling(ROLLING_DAYS).mean()\n",
        "\n",
        "# Plotting the data\n",
        "unique_pairs = df_plot['pair'].unique()\n",
        "for pair in unique_pairs:\n",
        "    df_subset = df_plot[df_plot['pair'] == pair]\n",
        "\n",
        "    # Extracting region labels for the current pair\n",
        "    region_treatment = df_subset['Region_treatment'].iloc[0]\n",
        "    region_control = df_subset['Region_control'].iloc[0]\n",
        "\n",
        "    # Plot for response values\n",
        "    plt.figure(figsize=(19, 3))\n",
        "    plt.gca().set_facecolor('#FFF9C4')  # Yellow background for response charts\n",
        "    plt.plot(df_subset['date'], df_subset['response_norm_treatment'], color='red', label=f'{config[\"response_name\"]} Treatment ({region_treatment})')\n",
        "    plt.plot(df_subset['date'], df_subset['response_norm_control'], color='gray', label=f'{config[\"response_name\"]} Control ({region_control})')\n",
        "\n",
        "    # Adding vertical lines\n",
        "    plt.axvline(test_start_date, color='green', linestyle='--', label='Test Start')\n",
        "    plt.axvline(test_end_date, color='red', linestyle='--', label='Test End')\n",
        "    plt.axvline(cooldown_end_date, color='blue', linestyle='--', label='Cooldown End')\n",
        "    plt.axvline(design_eval_start_date, color='purple', linestyle='--', label='Design Eval Start')\n",
        "    plt.axvline(design_eval_end_date, color='orange', linestyle='--', label='Design Eval End')\n",
        "\n",
        "    # Setting legend on the left side\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "    plt.title(f'{config[\"response_name\"]} for Pair {pair}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel(f'{config[\"response_name\"]} Values')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Plot for cost values\n",
        "    plt.figure(figsize=(19, 3))\n",
        "    plt.gca().set_facecolor('#E3F2FD')  # Blue background for cost charts\n",
        "    plt.plot(df_subset['date'], df_subset['cost_norm_treatment'], color='red', label=f'Cost Treatment ({region_treatment})')\n",
        "    plt.plot(df_subset['date'], df_subset['cost_norm_control'], color='gray', label=f'Cost Control ({region_control})')\n",
        "\n",
        "    # Adding vertical lines\n",
        "    plt.axvline(test_start_date, color='green', linestyle='--', label='Test Start')\n",
        "    plt.axvline(test_end_date, color='red', linestyle='--', label='Test End')\n",
        "    plt.axvline(cooldown_end_date, color='blue', linestyle='--', label='Cooldown End')\n",
        "    plt.axvline(design_eval_start_date, color='purple', linestyle='--', label='Design Eval Start')\n",
        "    plt.axvline(design_eval_end_date, color='orange', linestyle='--', label='Design Eval End')\n",
        "\n",
        "    # Setting legend on the left side\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "    plt.title(f'Cost for Pair {pair}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Cost Values')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('--------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blI6wHf1ZEMS"
      },
      "source": [
        "## âœ”ï¸ (optional) Charting - with difference colors [experimental]\n",
        "\n",
        "This is an alternative method to create the chart, where the difference (incrementality) is colored. This gives a better indication of the amount of incrementality, but looks a bit messier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XztzK5sUZOVE",
        "outputId": "5ae62c35-87bd-4d45-b308-f39dcb2e5005"
      },
      "outputs": [],
      "source": [
        "df_plot = pairs_df.copy()\n",
        "\n",
        "# âš™ï¸ Option to smootth the results\n",
        "SMOOTH_RESULTS = False\n",
        "ROLLING_DAYS = 4 # Default 4 if enabled, more days = smoother\n",
        "\n",
        "if (SMOOTH_RESULTS):\n",
        "    df_plot['response_norm_treatment'] = df_plot['response_norm_treatment'].rolling(ROLLING_DAYS).mean()\n",
        "    df_plot['response_norm_control'] = df_plot['response_norm_control'].rolling(ROLLING_DAYS).mean()\n",
        "    df_plot['cost_norm_treatment'] = df_plot['cost_norm_treatment'].rolling(ROLLING_DAYS).mean()\n",
        "    df_plot['cost_norm_control'] = df_plot['cost_norm_control'].rolling(ROLLING_DAYS).mean()\n",
        "print(\"Blue area = incremental, red area = anti incremental\")\n",
        "\n",
        "# Plotting the data\n",
        "unique_pairs = df_plot['pair'].unique()\n",
        "for pair in unique_pairs:\n",
        "    df_subset = df_plot[df_plot['pair'] == pair]\n",
        "\n",
        "    # Extracting region labels for the current pair\n",
        "    region_treatment = df_subset['Region_treatment'].iloc[0]\n",
        "    region_control = df_subset['Region_control'].iloc[0]\n",
        "\n",
        "    # Plot for response values\n",
        "    plt.figure(figsize=(19, 3))\n",
        "    plt.gca().set_facecolor('#FFF9C4')\n",
        "    plt.plot(df_subset['date'], df_subset['response_norm_treatment'], color='red', label=f'Response Treatment ({region_treatment})')\n",
        "    plt.plot(df_subset['date'], df_subset['response_norm_control'], color='gray', label=f'Response Control ({region_control})')\n",
        "\n",
        "    # Filling the area between the lines\n",
        "    plt.fill_between(df_subset['date'], df_subset['response_norm_treatment'], df_subset['response_norm_control'],\n",
        "                     where=(df_subset['response_norm_treatment'] > df_subset['response_norm_control']),\n",
        "                     facecolor='red', alpha=0.3, interpolate=True)\n",
        "\n",
        "    plt.fill_between(df_subset['date'], df_subset['response_norm_treatment'], df_subset['response_norm_control'],\n",
        "                     where=(df_subset['response_norm_treatment'] <= df_subset['response_norm_control']),\n",
        "                     facecolor='blue', alpha=0.3, interpolate=True)\n",
        "\n",
        "    # Adding vertical lines\n",
        "    plt.axvline(test_start_date, color='red', linestyle='--', label='Test Start')\n",
        "    plt.axvline(test_end_date, color='red', linestyle='--', label='Test End')\n",
        "    plt.axvline(cooldown_end_date, color='blue', linestyle='--', label='Cooldown End')\n",
        "    plt.axvline(design_eval_start_date, color='purple', linestyle='--', label='Design Eval Start')\n",
        "    plt.axvline(design_eval_end_date, color='orange', linestyle='--', label='Design Eval End')\n",
        "\n",
        "    # Setting legend on the left side\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "    plt.title(f'Response by Date for Pair {pair}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Response Values')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(19, 3))\n",
        "    plt.gca().set_facecolor('#E3F2FD')\n",
        "    plt.plot(df_subset['date'], df_subset['cost_norm_treatment'], color='red', label=f'Cost Treatment ({region_treatment})')\n",
        "    plt.plot(df_subset['date'], df_subset['cost_norm_control'], color='gray', label=f'Cost Control ({region_control})')\n",
        "\n",
        "    # Filling the area between the lines for cost\n",
        "    plt.fill_between(df_subset['date'], df_subset['cost_norm_treatment'], df_subset['cost_norm_control'],\n",
        "                     where=(df_subset['cost_norm_treatment'] > df_subset['cost_norm_control']),\n",
        "                     facecolor='red', alpha=0.3, interpolate=True)\n",
        "\n",
        "    plt.fill_between(df_subset['date'], df_subset['cost_norm_treatment'], df_subset['cost_norm_control'],\n",
        "                     where=(df_subset['cost_norm_treatment'] <= df_subset['cost_norm_control']),\n",
        "                     facecolor='blue', alpha=0.3, interpolate=True)\n",
        "\n",
        "    # Adding vertical lines\n",
        "    plt.axvline(test_start_date, color='red', linestyle='--', label='Test Start')\n",
        "    plt.axvline(test_end_date, color='red', linestyle='--', label='Test End')\n",
        "    plt.axvline(cooldown_end_date, color='blue', linestyle='--', label='Cooldown End')\n",
        "    plt.axvline(design_eval_start_date, color='purple', linestyle='--', label='Design Eval Start')\n",
        "    plt.axvline(design_eval_end_date, color='orange', linestyle='--', label='Design Eval End')\n",
        "\n",
        "    # Setting legend on the left side\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "    plt.title(f'Cost by Date for Pair {pair}')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Cost Values')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print('--------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "645zQaSTbTa1"
      },
      "source": [
        "## âœ”ï¸ (optional) Statistical validations\n",
        "\n",
        "Useful to compare different settings. Run all these cells first to get the incrementality values at the end.\n",
        "\n",
        "- Here you need high correlations and low MSE\n",
        "- When using `max` or `smooth_max` it's best to choose the model with lowest MSE total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsi4xdn3OOe8",
        "outputId": "c513f599-a75d-4a35-9de8-86e1b48146fb"
      },
      "outputs": [],
      "source": [
        "# Prepare function for metrics\n",
        "corr_df = pairs_df.copy()\n",
        "\n",
        "def calculate_metrics_for_period(group, start_date, end_date):\n",
        "    metrics = {}\n",
        "    # Filter the group for the specified period\n",
        "    period_data = group[(group['date'] >= start_date) & (group['date'] <= end_date)]\n",
        "\n",
        "    for col in ['cost', 'response']:\n",
        "        treatment_col = f'{col}_norm_treatment'\n",
        "        control_col = f'{col}_norm_control'\n",
        "\n",
        "        corr = period_data[treatment_col].corr(period_data[control_col])\n",
        "        metrics[f'{col}_pcorr'] = corr\n",
        "\n",
        "        mse = mean_squared_error(period_data[treatment_col], period_data[control_col])\n",
        "        metrics[f'{col}_mse'] = mse\n",
        "\n",
        "    return pd.Series(metrics)\n",
        "\n",
        "design_period_results = corr_df.groupby('pair').apply(calculate_metrics_for_period, design_eval_start_date, design_eval_end_date).reset_index()\n",
        "test_period_results = corr_df.groupby('pair').apply(calculate_metrics_for_period, test_start_date, test_end_date).reset_index()\n",
        "\n",
        "total_cost_mse = design_period_results['cost_mse'].sum()\n",
        "print(\"Total of cost_mse     :\", total_cost_mse)\n",
        "\n",
        "total_response_mse = design_period_results['response_mse'].sum()\n",
        "print(\"Total of response_mse :\", total_response_mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gA1zMqVNpf-"
      },
      "source": [
        "## âž– Incrementality values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "pxszyGxNk3ZB",
        "outputId": "f9ff726d-ef7f-461f-ebe9-5e93d5879907"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "def printm(c): # Utility function\n",
        "    return display(Markdown((c)))\n",
        "\n",
        "C_S = '' # âš™ï¸ Currency symbol, leave empty '' or curency with space 'â‚¬ '\n",
        "diff_df = pairs_df.copy()\n",
        "\n",
        "# Calculate total differences\n",
        "diff_df['cost_norm_diff'] = diff_df['cost_norm_treatment'] - diff_df['cost_norm_control']\n",
        "diff_df['response_norm_diff'] = diff_df['response_norm_treatment'] - diff_df['response_norm_control']\n",
        "\n",
        "# # Filter and denormalize! So that's the absolute difference from the normalized control baseline\n",
        "test_period_df = diff_df[(diff_df['date'] >= test_start_date) & (diff_df['date'] <= test_end_date)].copy()\n",
        "test_period_df['response_abs_diff'] = test_period_df['response_norm_diff'] * test_period_df['response_treatment']\n",
        "test_period_df\n",
        "\n",
        "grouped = test_period_df.groupby('pair')\n",
        "results = {}\n",
        "\n",
        "for pair_id, group in grouped:\n",
        "    test_period_group = group[(group['date'] >= test_start_date) & (group['date'] <= test_end_date)]\n",
        "\n",
        "    norm_cost_diff = test_period_group['cost_norm_diff'].mean() # not used\n",
        "    norm_response_diff = test_period_group['response_norm_diff'].mean()\n",
        "    abs_response_diff = test_period_group['response_abs_diff'].sum()\n",
        "    abs_response_diff_avg = test_period_group['response_abs_diff'].mean()\n",
        "    abs_response_avg = test_period_group['response_treatment'].mean()\n",
        "\n",
        "    region_treatment = group['Region_treatment'].iloc[0]\n",
        "    region_control = group['Region_control'].iloc[0]\n",
        "\n",
        "    # Display\n",
        "    printm(f'''### Pair {pair_id}: {region_control} (control) - {region_treatment} (treatment)\n",
        "\n",
        "Effect in test period: {C_S}{round(abs_response_diff)}\n",
        "\n",
        "Relative effect: {round(norm_response_diff * 100, 1)}%''')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZBR2yVT_tzaI",
        "8z75UvOFG3I-",
        "wIwWl118HAFL",
        "gC7M3altG8yl",
        "NZltwEuZHC-f",
        "rxpSWmPfiCuA",
        "blI6wHf1ZEMS"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
